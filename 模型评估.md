
author:young<br>
模型评估、正则化<br>


## 过拟合&欠拟合
https://blog.csdn.net/weixin_41882890/article/details/107008400<br>
（1.）解释一下过拟合和欠拟合，怎么发现过拟合问题，怎么解决过拟合?<br>
欠拟合：模型在训练集上就表现很差，没法学习到数据背后的规律。
过拟合：训练误差和测试误差之间的差距太大，泛化能力差。

欠拟合(高偏差)：模型复杂度过低、特征量过少。
过拟合(高方差)：样本太少、



建模样本选取有误，如样本数量太少，选样方法错误，样本标签错误等，导致选取的样本数据不足以代表预定的分类规则
样本噪音干扰过大，使得机器将部分噪音认为是特征从而扰乱了预设的分类规则
假设的模型无法合理存在，或者说是假设成立的条件实际并不成立
参数太多，模型复杂度过高
对于决策树模型，如果我们对于其生长没有合理的限制，其自由生长有可能使节点只包含单纯的事件数据(event)或非事件数据(no event)，使其虽然可以完美匹配（拟合）训练数据，但是无法适应其他数据集
对于神经网络模型：a)对样本数据可能存在分类决策面不唯一，随着学习的进行,，BP算法使权值可能收敛过于复杂的决策面；b)权值学习迭代次数足够多(Overtraining)，拟合了训练数据中的噪声和训练样例中没有代表性的特征






（2.）模型欠拟合的时候怎么处理？<br>
1. 模型复杂化
对同一个算法复杂化。例如回归模型添加更多的高次项，增加决策树的深度，增加神经网络的隐藏层数和隐藏单元数等。弃用原来的算法，使用一个更加复杂的算法或模型。例如用神经网络来替代线性回归，用随机森林来代替决策树等

2. 增加更多的特征，使输入数据具有更强的表达能力
特征挖掘十分重要，尤其是具有强表达能力的特征，往往可以抵过大量的弱表达能力的特征。特征的数量往往并非重点，质量才是，总之强特最重要。能否挖掘出强特，还在于对数据本身以及具体应用场景的深刻理解，往往依赖于经验

3. 调整参数和超参数
超参数包括：神经网络中：学习率、学习衰减率、隐藏层数、隐藏层的单元数、Adam优化算法中的β1和β2参数、batch_size数值等。其他算法中：随机森林的树数量，k-means中的cluster数，正则化参数λ等。

4. 增加训练数据往往没有用
欠拟合本来就是模型的学习能力不足，增加再多的数据给它训练它也没能力学习好

5. 降低正则化约束
正则化约束是为了防止模型过拟合，如果模型压根不存在过拟合而是欠拟合了，那么就考虑是否降低正则化参数λ或者直接去除正则化项


（3.）数据集小的时候该注意什么问题？<br>
过拟合


（4.）常用防止过拟合的方法<br>
https://www.bilibili.com/video/BV1j441187FF<br>
a.) 正则化项（Forbenius norm）：减小凸优化的搜索范围<br>
b.) dropout（inverted dropout）：期望不变，不失活的节点值/失活比例；集成学习思想<br>
c.) 数据集增大（data augmentation）<br>
d.) 早停（early stopping）：权衡tain和dev集合的偏差方差<br>

（5.）方差&偏差
https://www.bilibili.com/video/BV1gb41137Nx<br>
方差：train和dev的评估差异大，过拟合；偏差：错误率大，欠拟合<br>


## 正则化
（1.）L1正则化和L2正则化的区别和公式分别是什么?<br>
L1 正则化就是在 loss function 后边所加正则项为 L1 范数，加上 L1 范数容易得到稀疏解（0 比较多）。L2 正则化就是 loss function 后边所加正则项为 L2 范数的平方，加上 L2 正则相比于 L1 正则来说，得到的解比较平滑（不是稀疏），但是同样能够保证解中接近于 0（但不是等于 0，所以相对平滑）的维度比较多，降低模型的复杂度。<br>
L1正则的本质其实是为模型增加了“模型参数服从零均值拉普拉斯分布”这一先验知识。L2正则的本质其实是为模型增加了“模型参数服从零均值正态分布”这一先验知识。<br>

（2.）huber函数了解吗？和L1、L2比起来优势是啥？<br>


（3.）L1会使得特征系数稀疏化，为什么呢（岭回归和Lasso回归的区别）?<br>
https://zhuanlan.zhihu.com/p/74874291<br>
如果不加 L1 和 L2 正则化的时候，对于线性回归这种目标函数凸函数的话，我们最终的结果就是最里边的紫色的小圈圈等高线上的点。当加入 L1 正则化的时候，我们先画出|w1|+|w2|=F的图像，也就是一个菱形。现在的目标是不仅是原曲线算的值要小（越来越接近中心的紫色圈圈），还要使得这个菱形越小越好（F 越小越好）。那么还和原来一样的话，过中心紫色圈圈的那个菱形明显很大，因此我们要取到一个恰好的值。**最终加入 L1 范数得到的解一定是某个菱形和某条原函数等高线的切点。**经过观察可以看到，几乎对于很多原函数等高曲线，和某个菱形相交的时候及其容易相交在坐标轴。<br>

（4.）Lasso回归有特征选择的作用，有哪些 特征选择的方式?<br>
树模型选择重要特征，


## 归一化
（1.）batch-normalization<br>
https://www.bilibili.com/video/BV1bx411V798/?spm_id_from=333.788.videocard.1<br>
为了同一batch数据样本的各个特征列 都符合 N(0,1)，在圆形搜索区域里，统一的学习率 优化，加快训练。<br>
a.) internal covariate shift，不同层取值范围不一致，要求学习率设置很小-可以保证相邻层调整对齐；
有了batch-normalization后，学习率可以设置大一些，训练会更快<br>
b.) 不用batch-normalization调整，特征取值很大或者很小，sigmoid激活函数会出现梯度消失<br>
c.) 加了batch-normalization后，受 参数的初始化 影响会减小<br>
d.) 做了batch-normalization有一些对抗过拟合的效果，因为把数据都调整到N(0,1)，即使有偏差较大的噪音数据进来，也不会使训练受影响，学到冗余信息<br>
d.) batch-normalization主要作用是在训练效果不好时，起到较大作用<br>
对小batch不适合，因为对每个batch归一化的均值和方差统计不准<br>
训练时：每个batch的均值和方差；测试时：(a)全量训练集数据的均值和方差，（b）对过去每个batch的均值方差记录加权，给靠近训练结束位置的方差较大权重。<br>

（2.）介绍Batch Norm，Layer Norm<br>



（3.）批量归一化的思想，还了解其他归一化吗？<br>






## 模型评估
（1.）机器学习中一般怎么衡量模型效果(评价指标)？auc值怎么理解？<br>


（2.）给你M个正样本，N个负样本，以及他们的预测值P，求AUC。（写完之后接问：AUC究竟在衡量模型什么能力？如果现在所有预测值都乘1.2，AUC是否会变化？）<br>


（3.）实现求auc的过程（输入就是instance的score和对应label）<br>




## 模型调优
（1.）影响模型效果的因素有什么，并排个序<br>


（2.）当模型的性能不好时，如何分析模型的瓶颈？<br>














































